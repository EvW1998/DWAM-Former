{
    "Transformer": {
        "num_layers": 12,
        "num_heads": 8,
        "official": false,
        "dropout": 0.1, 
        "attention_dropout": 0.1
    },

    "DWAM-Former": {
        "num_layers": [2, 2, 4, 4],
        "expand": [1, 1, 2, -1],
        "num_heads": 8,
        "dropout": 0.1, 
        "attention_dropout": 0.1
    }
}
